# -*- coding: utf-8 -*-
"""Logistic_Regression_ElectricityPricePrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1doHWpfvtF_GOWrdwst3qbCN2Ulz5uDUU
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import pandas as pd
import pylab as pl
import numpy as np
# %matplotlib inline

"""LR"""

from google.colab import drive
drive .mount('/content/drive')

data=pd.read_csv("/content/drive/MyDrive/electricity.csv")
data.head()

data.info()

#convert these string values to float values
data["ForecastWindProduction"] = pd.to_numeric(data["ForecastWindProduction"], errors= 'coerce')
data["SystemLoadEA"] = pd.to_numeric(data["SystemLoadEA"], errors= 'coerce')
data["SMPEA"] = pd.to_numeric(data["SMPEA"], errors= 'coerce')
data["ORKTemperature"] = pd.to_numeric(data["ORKTemperature"], errors= 'coerce')
data["ORKWindspeed"] = pd.to_numeric(data["ORKWindspeed"], errors= 'coerce')
data["CO2Intensity"] = pd.to_numeric(data["CO2Intensity"], errors= 'coerce')
data["ActualWindProduction"] = pd.to_numeric(data["ActualWindProduction"], errors= 'coerce')
data["SystemLoadEP2"] = pd.to_numeric(data["SystemLoadEP2"], errors= 'coerce')
data["SMPEP2"] = pd.to_numeric(data["SMPEP2"], errors= 'coerce')

data.isnull().sum()
#No of null values for each feature

data = data.dropna()

data.isnull().sum()

data.describe()

#the correlation between all the columns in the dataset
import seaborn as sns
import matplotlib.pyplot as plt
correlations = data.corr(method='pearson')
plt.figure(figsize=(16, 12))
sns.heatmap(correlations, cmap="coolwarm", annot=True)
plt.show()

x = data[["Day", "Month", "ForecastWindProduction", "SystemLoadEA",
          "SMPEA", "ORKTemperature", "ORKWindspeed", "CO2Intensity",
          "ActualWindProduction", "SystemLoadEP2"]]
y = data["SMPEP2"]

# Printing DataFrame Before sorting Continuous
# to Categories
df1 = pd.DataFrame(y)
print("Before: ")
print(df1)
df1['Label'] = pd.cut(x=data['SMPEP2'], bins=[-47,50,1000],labels=['No','Yes'])

# Printing DataFrame after sorting Continuous to
# Categories
print("After: ")
print(df1)

# Check the number of values in each bin
#print("Categories: ")
#print(df1['Label'].value_counts())

# import required modules
import pandas as pd
# converting to binary data
df_one = pd.get_dummies(df1['Label'])
# print(df_one)

# display result
df_two = pd.concat((df_one, df1), axis=1)
df_two = df_two.drop(["Label"], axis=1)
df_two = df_two.drop(["Yes"], axis=1)
result = df_two.rename(columns={"No": "Label"})
print(result)

import numpy as np
from sklearn import metrics, svm
from sklearn.linear_model import LogisticRegression
from sklearn import preprocessing
from sklearn import utils

from sklearn import preprocessing
X_new=preprocessing.StandardScaler().fit(x).transform(x)
X_new[0:5]

y_new=result['Label']

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(X_new, y_new,test_size=0.2,random_state=42)

print('Shape of x_new training set {}'.format(xtrain.shape),'&',' Size of Y training set {}'.format(ytrain.shape))

print('Shape of X_new testing set {}'.format(xtest.shape),'&',' Size of Y testing set {}'.format(ytest.shape))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
LR = LogisticRegression(C=0.01, solver='liblinear').fit(xtrain,ytrain)
LR

y_hat=LR.predict(xtest)

y_hat

yhat_prob = LR.predict_proba(xtest)
yhat_prob

from sklearn.metrics import classification_report, confusion_matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
print(confusion_matrix(ytest, y_hat, labels=[1,0]))

# Compute confusion matrix
cnf_matrix = confusion_matrix(ytest, y_hat, labels=[1,0])
np.set_printoptions(precision=2)


# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['Label=1','Label=0'],normalize= False,  title='Confusion matrix')

print (classification_report(ytest, y_hat))

from sklearn import metrics
print("Accuracy: ", metrics.accuracy_score(ytest, y_hat))

# Commented out IPython magic to ensure Python compatibility.
x = xtest
y = ytest
print("Residual sum of squares: %.2f"
#       % np.mean((y_hat - y) ** 2))

# Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % LR.score(x, y))

from sklearn import metrics
from sklearn.metrics import mean_absolute_error
metrics.mean_absolute_error(y, y_hat)

from sklearn import metrics
from sklearn.metrics import mean_squared_error
metrics.mean_squared_error(y, y_hat)

features = np.array([[10, 12, 54.10, 4241.05, 49.56, 9.0, 14.8, 491.32, 54.0, 4426.84]])
LR.predict(features)

# ROC Curve with logistic regression
from sklearn.metrics import roc_curve
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
y_pred_prob = LR.predict_proba(xtest)[:,1]
fpr, tpr, thresholds = roc_curve(ytest, y_pred_prob)
# Plot ROC curve
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC')
plt.show()